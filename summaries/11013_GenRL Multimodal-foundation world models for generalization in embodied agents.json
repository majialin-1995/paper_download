{
  "phenomenon": "GenRL框架通过多模态基础世界模型（MFWMs）将基础模型的视频-语言空间与生成世界模型的潜在空间连接和对齐，仅需视觉数据即可实现。",
  "problem": [
    "(1) 学习通用型体现代理（embodied agents）以解决不同领域的多种任务是一个长期存在的问题。",
    "(2) 强化学习（RL）难以扩展，因为它需要为每个任务设计复杂的奖励机制。",
    "(3) 当前的基础视觉语言模型（VLMs）通常需要微调或其他适应措施才能在体现上下文中采用，由于显著的领域差距。",
    "(4) 在这些领域中缺乏多模态数据是开发体现应用基础模型的障碍。"
  ],
  "mechanism": [
    "(1) 提出多模态基础世界模型（MFWMs），能够连接和对齐基础VLMs的表示与生成世界模型的潜在空间，无需任何语言注释。",
    "(2) 引入一个RL目标，通过在潜在空间中匹配提示，使代理能够在想象中学习完成指定任务。",
    "(3) 通过引入无数据策略学习策略，为使用生成世界模型的基础策略学习奠定了基础。"
  ],
  "result": {
    "dataset_environment": "在运动和操作领域的多任务基准测试中",
    "performance": "GenRL能够从语言和视觉提示中实现多任务泛化。"
  }
}