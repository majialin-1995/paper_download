{
  "phenomenon": "多智能体强化学习（Multi-Agent Reinforcement Learning, MARL）在合作任务中的成功应用，但在异构场景中面临挑战，因为之前的工作简单地通过禁用参数共享来实现智能体专业化。",
  "problem": [
    "(1) 异构场景中智能体专业化的挑战；",
    "(2) 传统差异测量缺乏稳定性和方向性；",
    "(3) 多智能体任务中的探索空间复杂性增加。"
  ],
  "mechanism": [
    "(1) 提出顺序更新方案，通过鼓励智能体从前面的智能体学习来自然多样化智能体；",
    "(2) 提出多智能体差异策略优化（MADPO），配备相互策略差异最大化框架；",
    "(3) 使用条件Cauchy-Schwarz差异来提供熵引导的探索激励。"
  ],
  "result": {
    "datasets": [
      "Multi-Agent Mujoco (MA-Mujoco)",
      "Bi-DexHands"
    ],
    "performance": [
      "MADPO在两个具有各种异构场景的挑战性多智能体任务中优于最先进的顺序更新方法。",
      "在MA-Mujoco和Bi-DexHands上的广泛实验表明，提出的方法在样本效率和性能上均优于现有方法。"
    ]
  }
}