{
  "phenomenon": "在现实世界的多智能体场景中，常常涉及混合动机，需要既能进行利他合作又能自我保护以防止被利用的智能体。然而，现有的方法往往难以同时实现这两个目标。",
  "problem": [
    "(1) 现有方法难以在混合动机游戏中同时实现利他合作和自我保护。",
    "(2) 集中式训练与分散式执行（CTDE, Centralized Training and Decentralized Execution）方法在混合动机游戏中不切实际。",
    "(3) 单纯以分散方式训练自利智能体可能收敛到局部最优，无法最大化个体利益。"
  ],
  "mechanism": [
    "(1) 提出LASE（基于共情学习平衡利他与自利），一种分布式多智能体强化学习算法，通过礼物交换促进利他合作，同时避免被其他智能体利用。",
    "(2) LASE通过反事实推理估计社交关系，动态调整给其他智能体的礼物分配。",
    "(3) 引入视角采取模块，通过将LASE的局部观察转换为其他智能体的模拟观察，预测其他智能体的策略。"
  ],
  "result": {
    "datasets": [
      "迭代囚徒困境（IPD）",
      "硬币游戏（Coingame）",
      "清理游戏（Cleanup）",
      "顺序猎鹿游戏（SSH）",
      "顺序雪堆游戏（SSG）"
    ],
    "performance": [
      "在IPD中，LASE智能体以约93%的概率合作，集体奖励高。",
      "在SSH和SSG中，LASE几乎达到总奖励的上限。",
      "在Coingame和Cleanup中，LASE有效避免了次优均衡。",
      "LASE在扩展的Cleanup和SSG中展示了处理更复杂环境的能力。"
    ]
  }
}