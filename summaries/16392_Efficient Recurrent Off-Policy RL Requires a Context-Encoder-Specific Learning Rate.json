{
  "phenomenon": "部分可观察马尔可夫决策过程（POMDPs）中，状态不完全可观察，导致传统强化学习（RL）方法难以有效处理。",
  "problem": [
    "(1) 由于RNN的自回归性质，即使RNN参数的微小变化也会在长轨迹上产生大的输出变化，导致训练不稳定。",
    "(2) 传统RNN稳定化技术（如梯度裁剪和截断反向传播）无法可靠地提高RL训练稳定性。"
  ],
  "mechanism": [
    "(1) 提出使用上下文编码器特定学习率（Context-Encoder-Specific Learning Rate, RESeL），对上下文编码器使用较低的学习率，而对其他MLP层保持正常学习率，以确保前者的稳定性同时保持后者的训练效率。",
    "(2) 将RESeL技术与现有的离策略RL方法结合，开发了RESeL算法。"
  ],
  "result": {
    "datasets": [
      "18个POMDP任务（包括经典、元RL和信用分配场景）",
      "5个MDP运动任务"
    ],
    "performance": [
      "在POMDP任务中，RESeL显著提高了训练稳定性，并在性能上超越了先前的循环RL基线。",
      "在MDP任务中，RESeL与最先进的方法竞争甚至超越。",
      "消融研究突出了对上下文编码器应用不同学习率的必要性。"
    ]
  }
}