{
  "phenomenon": "训练能够与人类零协调的代理是多智能体强化学习（MARL）中的一个关键任务。",
  "problem": [
    "(1) 当前算法专注于训练模拟人类伙伴策略，然后用于训练合作者代理。",
    "(2) 模拟人类通常无法覆盖现实世界中人们使用的多样策略和风格，导致合作者代理与真实人类协调不佳。",
    "(3) 人类行为的不确定性和多样性，包括广泛的偏好、能力和意图，使得训练能够与人类良好合作的人工代理成为一项重大挑战。"
  ],
  "mechanism": [
    "(1) 学习人类伙伴的生成模型可以有效解决这一问题。",
    "(2) 该模型学习人类的潜在变量表示，可以视为编码人类的独特策略、意图、经验或风格。",
    "(3) 通过从潜在空间采样，可以使用生成模型产生不同的伙伴来训练合作者代理。"
  ],
  "result": {
    "dataset": "Overcooked",
    "performance": "GAMMA方法在真实人类队友的评估中一致提高了性能，无论生成模型是在模拟群体还是人类数据集上训练的。此外，提出了一种从生成模型中进行后验采样的方法，偏向于人类数据，使我们能够仅用少量昂贵的人类交互数据有效提高性能。"
  }
}