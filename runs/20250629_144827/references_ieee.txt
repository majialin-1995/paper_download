Yiqin Yang, Quanwei Wang, Chenghao Li, Hao Hu, Chengjie Wu, Yuhua Jiang, Dianyu Zhong, Ziyou Zhang, Qianchuan Zhao, Chongjie Zhang, and Bo XU, "Fewer May Be Better: Enhancing Offline Reinforcement Learning with Reduced Dataset," in Proceedings of the International Conference on Learning Representations (ICLR), 2024, pp. 1-23.
Tian-Shuo Liu, Xu-Hui Liu, Ruifeng Chen, Lixuan Jin, Pengyuan Wang, Zhilong Zhang, and Yang Yu, "Semantic Temporal Abstraction via Vision-Language Model Guidance for Efficient Reinforcement Learning," in Proceedings of the International Conference on Learning Representations (ICLR), 2024, pp. 1-28.
Michael Matthews, Michael Beukman, Chris Lu, and Jakob Nicolaus Foerster, "Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks," in Proceedings of the International Conference on Learning Representations (ICLR), 2024, pp. 1-50.
Brent A. Wallace and Jennie Si, "Integral Performance Approximation for Continuous-Time Reinforcement Learning Control," in Proceedings of the International Conference on Learning Representations (ICLR), 2024, pp. 1-42.
Ayano Hiranaka, Shang-Fu Chen, Chieh-Hsin Lai, Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, Shao-Hua Sun, and Yuki Mitsufuji, "HERO: Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning," in Proceedings of the International Conference on Learning Representations (ICLR), 2024, pp. 1-30.